from openai import OpenAI
client = OpenAI()


import os
import glob
def get_latest_audio_file(audio_dir="audio_archive"):
    """ä»æŒ‡å®šç›®å½•è·å–æœ€æ–°çš„éŸ³é¢‘æ–‡ä»¶"""
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    audio_archive_path = os.path.join(project_root, audio_dir)
    
    if not os.path.exists(audio_archive_path):
        print(f"âŒ éŸ³é¢‘å­˜æ¡£ç›®å½•ä¸å­˜åœ¨: {audio_archive_path}")
        return None
    
    # æŸ¥æ‰¾æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    audio_patterns = ['*.wav', '*.mp3', '*.m4a', '*.flac', '*.ogg']
    audio_files = []
    
    for pattern in audio_patterns:
        audio_files.extend(glob.glob(os.path.join(audio_archive_path, pattern)))
    
    if not audio_files:
        print(f"âŒ åœ¨ {audio_archive_path} ä¸­æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        return None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(audio_files, key=os.path.getmtime)
    print(f"ğŸµ æ‰¾åˆ°æœ€æ–°éŸ³é¢‘æ–‡ä»¶: {os.path.basename(latest_file)}")
    return latest_file


# openai å®˜æ–¹apiæµ‹è¯•
with open(get_latest_audio_file(), "rb") as f:
    resp = client.audio.transcriptions.create(
        model="gpt-4o-transcribe",   # æˆ– "gpt-4o-mini-transcribe"
        file=f,                      # å…³é”®ç‚¹ï¼šä¼ äºŒè¿›åˆ¶æ–‡ä»¶å¯¹è±¡
        # language="zh",             # è‹¥å·²çŸ¥è¯­è¨€å¯æ˜¾å¼æŒ‡å®š
        # temperature=0,             # å¯é€‰
    )
print(resp.text)

# proxy_on
# unset OPENAI_BASE_URL
# export OPENAI_API_KEY=$OFFICIAL_OPENAI_API_KEY